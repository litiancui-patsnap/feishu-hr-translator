"""
LLM Translator MCP Server

Provides AI-powered content translation and analysis capabilities.
Translates technical reports into plain language suitable for non-technical audiences (HR, executives).
"""

from __future__ import annotations

import asyncio
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.ai.qwen import QwenClient
from src.schemas import HRExtract, OKRAlignment, ReportIn


class LLMTranslatorServer:
    """
    MCP Server for AI-powered content translation and analysis.

    This server wraps the Qwen LLM client to provide:
    - Technical â†’ HR-friendly language translation
    - Risk extraction and assessment
    - OKR alignment inference
    - Next action generation

    Capabilities:
    - Tools: translate_to_hr_language, extract_risks, infer_okr_alignment, generate_next_actions
    - Resources: supported_models, prompt_templates
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "qwen-plus",
        api_mode: str = "text",
        timeout: float = 30.0,
    ):
        """
        Initialize LLM Translator Server.

        Args:
            api_key: DashScope API key (optional, can be set via env)
            model: Model name (qwen-plus, qwen-max, qwen-turbo)
            api_mode: API mode (text or compatible)
            timeout: Request timeout in seconds
        """
        self.api_key = api_key
        self.model = model
        self.api_mode = api_mode
        self.timeout = timeout
        self._client: Optional[QwenClient] = None

    def _get_client(self) -> QwenClient:
        """Lazy initialization of Qwen client."""
        if self._client is None:
            self._client = QwenClient(
                api_key=self.api_key,
                model=self.model,
                timeout=self.timeout,
                api_mode=self.api_mode,
                trust_env=False,
            )
        return self._client

    # ==================== MCP Tools ====================

    async def translate_to_hr_language(
        self,
        text: str,
        user_name: str = "Unknown User",
        period_type: str = "weekly",
        okr_context: Optional[str] = None,
        target_audience: str = "hr",
    ) -> Dict[str, Any]:
        """
        Translate technical report to HR-friendly language.

        This is the main MCP tool for content translation. It takes a technical
        report and transforms it into plain language suitable for non-technical readers.

        Args:
            text: Original technical report text
            user_name: Name of the person who wrote the report
            period_type: Report period (daily, weekly, monthly)
            okr_context: Optional OKR context/goals for the user
            target_audience: Target audience (hr, executive, board)

        Returns:
            {
                "summary": "Plain language summary (max 200 words)",
                "risks": [{"item": "...", "likelihood": "low|medium|high", "mitigation": "..."}],
                "needs": [{"topic": "...", "owner": "..."}],
                "okr_alignment": {
                    "hit_objectives": ["Objective 1", ...],
                    "hit_krs": ["Key Result 1", ...],
                    "gaps": ["Missing/behind area 1", ...],
                    "confidence": 0.0-1.0
                },
                "next_actions": ["Action 1", "Action 2", ...],
                "risk_level": "low|medium|high",
                "timestamp": "ISO timestamp"
            }

        Example:
            >>> result = await server.translate_to_hr_language(
            ...     text="æœ¬å‘¨å®Œæˆäº† API é‡æ„å’Œæ€§èƒ½ä¼˜åŒ–...",
            ...     user_name="å¼ ä¸‰",
            ...     period_type="weekly",
            ...     okr_context="æå‡ç³»ç»Ÿæ€§èƒ½å’Œç¨³å®šæ€§"
            ... )
            >>> print(result["summary"])
            "æœ¬å‘¨å®Œæˆäº†åå°æ¥å£ä¼˜åŒ–ï¼Œæå‡äº†ç³»ç»Ÿå“åº”é€Ÿåº¦..."
        """
        # Create ReportIn object
        report = ReportIn(
            user_id="mcp_user",
            user_name=user_name,
            raw_text=text,
            period_type=period_type,
            period_start="2025-01-01",  # Placeholder
            period_end="2025-01-07",
            message_ts=datetime.utcnow(),
        )

        # Generate HR extract
        client = self._get_client()
        hr_extract = await client.generate_hr_extract(
            report=report,
            okr_brief=okr_context or "æš‚æ—  OKR ä¿¡æ¯",
        )

        # Format response
        return {
            "summary": hr_extract.hr_summary,
            "risks": [
                {
                    "item": risk.item,
                    "likelihood": risk.likelihood,
                    "mitigation": risk.mitigation or "",
                }
                for risk in hr_extract.risks
            ],
            "needs": [
                {
                    "topic": need.topic,
                    "owner": need.owner or "",
                }
                for need in hr_extract.needs
            ],
            "okr_alignment": {
                "hit_objectives": hr_extract.okr_alignment.hit_objectives,
                "hit_krs": hr_extract.okr_alignment.hit_krs,
                "gaps": hr_extract.okr_alignment.gaps,
                "confidence": hr_extract.okr_alignment.confidence,
            },
            "next_actions": hr_extract.next_actions,
            "risk_level": hr_extract.risk_level,
            "timestamp": datetime.utcnow().isoformat(),
        }

    async def extract_risks(
        self,
        text: str,
        context: Optional[str] = None,
    ) -> List[Dict[str, str]]:
        """
        Extract risks from report text.

        Analyzes the report and identifies potential risks, blockers, or concerns.

        Args:
            text: Report text to analyze
            context: Optional context for risk assessment

        Returns:
            [
                {
                    "item": "Risk description",
                    "likelihood": "low|medium|high",
                    "mitigation": "Suggested mitigation strategy"
                },
                ...
            ]

        Example:
            >>> risks = await server.extract_risks(
            ...     text="é¡¹ç›®è¿›åº¦å»¶æœŸï¼Œä¾èµ–çš„ç¬¬ä¸‰æ–¹ API ä¸ç¨³å®š",
            ...     context="å…³é”®é¡¹ç›®ï¼Œéœ€æŒ‰æ—¶äº¤ä»˜"
            ... )
            >>> for risk in risks:
            ...     print(f"{risk['likelihood']}: {risk['item']}")
        """
        result = await self.translate_to_hr_language(
            text=text,
            okr_context=context,
        )
        return result["risks"]

    async def infer_okr_alignment(
        self,
        text: str,
        okr_context: str,
    ) -> Dict[str, Any]:
        """
        Infer OKR alignment from report text.

        Analyzes the report against provided OKR context to determine:
        - Which objectives/KRs are being addressed
        - Which OKRs are falling behind or not covered
        - Confidence level of the alignment

        Args:
            text: Report text to analyze
            okr_context: User's OKR context/goals

        Returns:
            {
                "hit_objectives": ["Achieved objective 1", ...],
                "hit_krs": ["Achieved key result 1", ...],
                "gaps": ["Missing/behind area 1", ...],
                "confidence": 0.0-1.0
            }

        Example:
            >>> alignment = await server.infer_okr_alignment(
            ...     text="å®Œæˆäº†ç”¨æˆ·ç™»å½•åŠŸèƒ½å¼€å‘",
            ...     okr_context="Q1 ç›®æ ‡ï¼šå®Œæˆç”¨æˆ·è®¤è¯ç³»ç»Ÿ (KR: ç™»å½•ã€æ³¨å†Œã€å¯†ç é‡ç½®)"
            ... )
            >>> print(f"å·²å®Œæˆ: {alignment['hit_krs']}")
            >>> print(f"å¾…å®Œæˆ: {alignment['gaps']}")
        """
        result = await self.translate_to_hr_language(
            text=text,
            okr_context=okr_context,
        )
        return result["okr_alignment"]

    async def generate_next_actions(
        self,
        text: str,
        context: Optional[str] = None,
    ) -> List[str]:
        """
        Generate actionable next steps from report.

        Analyzes the report and suggests concrete, executable next actions.

        Args:
            text: Report text to analyze
            context: Optional context for action generation

        Returns:
            ["Action 1", "Action 2", ...]

        Example:
            >>> actions = await server.generate_next_actions(
            ...     text="å·²å®Œæˆç™»å½•åŠŸèƒ½ï¼Œä½†æ€§èƒ½æµ‹è¯•è¿˜æœªå¼€å§‹",
            ...     context="éœ€è¦åœ¨æœˆåº•å‰ä¸Šçº¿"
            ... )
            >>> for action in actions:
            ...     print(f"- {action}")
        """
        result = await self.translate_to_hr_language(
            text=text,
            okr_context=context,
        )
        return result["next_actions"]

    # ==================== MCP Resources ====================

    def get_supported_models(self) -> List[Dict[str, str]]:
        """
        Get list of supported LLM models.

        Returns:
            [
                {
                    "name": "qwen-max",
                    "provider": "dashscope",
                    "cost": "higher",
                    "description": "Most capable model"
                },
                ...
            ]
        """
        return [
            {
                "name": "qwen-max",
                "provider": "dashscope",
                "cost": "higher",
                "description": "Most capable Qwen model, best quality",
                "api_mode": "text",
            },
            {
                "name": "qwen-plus",
                "provider": "dashscope",
                "cost": "medium",
                "description": "Balanced performance and cost (recommended)",
                "api_mode": "compatible",
            },
            {
                "name": "qwen-turbo",
                "provider": "dashscope",
                "cost": "lower",
                "description": "Faster, lower cost, good for simple tasks",
                "api_mode": "compatible",
            },
            {
                "name": "qwen-long",
                "provider": "dashscope",
                "cost": "medium",
                "description": "Long context support (up to 10M tokens)",
                "api_mode": "compatible",
            },
        ]

    def get_prompt_templates(self) -> Dict[str, str]:
        """
        Get available prompt templates.

        Returns:
            {
                "system_prompt": "...",
                "user_prompt_template": "...",
                "constraints": "...",
            }
        """
        from src.ai.qwen import SYSTEM_PROMPT, USER_PROMPT_TEMPLATE

        return {
            "system_prompt": SYSTEM_PROMPT,
            "user_prompt_template": USER_PROMPT_TEMPLATE,
            "description": "Prompt templates used for HR-friendly translation",
            "language": "Chinese (Simplified)",
            "target_audience": "Non-technical HR/HRBP",
        }

    def get_translation_glossary(self) -> Dict[str, str]:
        """
        Get technical terms â†’ plain language glossary.

        Returns:
            {"API": "ç³»ç»Ÿæ¥å£/ç¨‹åºè¿æ¥é€šé“", ...}
        """
        return {
            "API": "ç³»ç»Ÿæ¥å£ / ç¨‹åºä¹‹é—´çš„è¿æ¥é€šé“",
            "SDK": "å¼€å‘å·¥å…·åŒ… / ç¨‹åºå¼€å‘å¥—ä»¶",
            "TDD/BDD": "æµ‹è¯•é©±åŠ¨å¼€å‘ / å…ˆå†™æµ‹è¯•å†å†™ä»£ç çš„æ–¹æ³•",
            "CI/CD": "è‡ªåŠ¨åŒ–éƒ¨ç½² / ä»£ç è‡ªåŠ¨ä¸Šçº¿æµç¨‹",
            "é‡æ„": "ä»£ç ä¼˜åŒ– / æ”¹è¿›ä»£ç è´¨é‡",
            "è§£è€¦": "æ¨¡å—åˆ†ç¦» / è®©å„éƒ¨åˆ†ç‹¬ç«‹è¿è¡Œ",
            "å¼‚æ­¥": "åå°å¤„ç† / ä¸é˜»å¡ç”¨æˆ·æ“ä½œ",
            "å¹¶å‘": "åŒæ—¶å¤„ç†å¤šä¸ªä»»åŠ¡",
            "PR/MR": "ä»£ç åˆå¹¶è¯·æ±‚ / æäº¤ä»£ç å®¡æŸ¥",
            "Bug": "ç¨‹åºé”™è¯¯ / åŠŸèƒ½å¼‚å¸¸",
            "Debug": "æ’æŸ¥é—®é¢˜ / æ‰¾å‡ºé”™è¯¯åŸå› ",
            "æ¡†æ¶": "å¼€å‘æ¡†æ¶ / å¼€å‘å·¥å…·é›†",
            "å‰ç«¯": "ç”¨æˆ·ç•Œé¢ / ç½‘é¡µæ˜¾ç¤ºéƒ¨åˆ†",
            "åç«¯": "æœåŠ¡å™¨ç¨‹åº / æ•°æ®å¤„ç†éƒ¨åˆ†",
            "æ•°æ®åº“": "æ•°æ®å­˜å‚¨ç³»ç»Ÿ",
            "ç¼“å­˜": "ä¸´æ—¶æ•°æ®å­˜å‚¨ / åŠ å¿«è®¿é—®é€Ÿåº¦",
            "æ¥å£": "è¿æ¥ç‚¹ / ä¸åŒç³»ç»Ÿçš„å¯¹æ¥æ–¹å¼",
        }


# ==================== MCP Server Integration ====================

def create_mcp_server() -> LLMTranslatorServer:
    """
    Factory function to create MCP server instance.

    This function is called by the MCP framework to instantiate the server.
    Configuration is read from environment variables or MCP config.
    """
    import os

    return LLMTranslatorServer(
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        model=os.getenv("QWEN_MODEL", "qwen-plus"),
        api_mode=os.getenv("QWEN_API_MODE", "text"),
        timeout=float(os.getenv("REQUEST_TIMEOUT_SECONDS", "30.0")),
    )


# ==================== CLI for testing ====================

async def _test_translation():
    """Test the translation functionality."""
    server = create_mcp_server()

    test_text = """
    æœ¬å‘¨å®Œæˆäº† WebApp çš„ TDD/BDD æµ‹è¯•æ¡†æ¶æ­å»ºï¼Œé‡æ„äº† API å±‚çš„å¼‚æ­¥è°ƒç”¨é€»è¾‘ï¼Œ
    ä¿®å¤äº† O2KR1 ç›¸å…³çš„ bug_num=t100755 é—®é¢˜ã€‚ä¸‹å‘¨è®¡åˆ’è¿›è¡Œæ€§èƒ½ä¼˜åŒ–ã€‚
    """

    print("ğŸ”„ æµ‹è¯• LLM Translator Server...")
    print(f"è¾“å…¥æ–‡æœ¬: {test_text.strip()}\n")

    result = await server.translate_to_hr_language(
        text=test_text,
        user_name="æµ‹è¯•ç”¨æˆ·",
        period_type="weekly",
        okr_context="æå‡æµ‹è¯•æ•ˆç‡å’Œè´¨é‡ï¼Œä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½",
    )

    print("âœ… ç¿»è¯‘ç»“æœ:")
    print(f"ğŸ“ HR æ€»ç»“: {result['summary']}\n")

    if result['risks']:
        print("âš ï¸ é£é™©é¡¹:")
        for risk in result['risks']:
            print(f"  - [{risk['likelihood']}] {risk['item']}")
            if risk['mitigation']:
                print(f"    ç¼“è§£æªæ–½: {risk['mitigation']}")
        print()

    if result['okr_alignment']['hit_krs']:
        print("ğŸ¯ å·²å®Œæˆçš„å…³é”®æˆæœ:")
        for kr in result['okr_alignment']['hit_krs']:
            print(f"  - {kr}")
        print()

    if result['okr_alignment']['gaps']:
        print("ğŸ“Œ å¾…æ¨è¿›çš„ç›®æ ‡:")
        for gap in result['okr_alignment']['gaps']:
            print(f"  - {gap}")
        print()

    if result['next_actions']:
        print("â¡ï¸ ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
        for action in result['next_actions']:
            print(f"  - {action}")
        print()

    print(f"ğŸ“Š é£é™©ç­‰çº§: {result['risk_level']}")
    print(f"ğŸ” OKR å¯¹é½ç½®ä¿¡åº¦: {result['okr_alignment']['confidence']:.0%}")


if __name__ == "__main__":
    # Run test
    asyncio.run(_test_translation())
